# -*- coding: utf-8 -*-
"""siglip.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wXorCpiJ2H3H-Bo-2zqBgwLyL_7R6D-v
"""

!wget -q http://images.cocodataset.org/zips/val2017.zip

!unzip -q val2017.zip

import os
import math
import torch
import pandas as pd
from PIL import Image
from tqdm.auto import tqdm

from transformers import AutoModel, AutoProcessor

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

SIGLIP_MODEL_ID = "google/siglip-base-patch16-256-multilingual"

siglip_model = AutoModel.from_pretrained(SIGLIP_MODEL_ID).to(DEVICE).eval()
siglip_processor = AutoProcessor.from_pretrained(SIGLIP_MODEL_ID)

def resolve_image_path(p, image_roots=(".",), strip_prefixes=()):
    p_raw = str(p).strip()
    if not p_raw:
        return None

    if isinstance(image_roots, (str, os.PathLike)):
        roots = [str(image_roots)]
    else:
        roots = [str(r) for r in image_roots if str(r)]

    def _exists(path):
        return path is not None and os.path.exists(path)

    def _try(path):
        path = os.path.normpath(path)
        if _exists(path):
            return path
        for root in roots:
            cand = os.path.normpath(os.path.join(root, path))
            if _exists(cand):
                return cand
        return None

    found = _try(p_raw)
    if found:
        return found

    variants = set()
    for pref in strip_prefixes:
        if p_raw.startswith(pref):
            v = p_raw[len(pref):].lstrip("/\\")
            variants.add(v)

    for likely in ("/content/", "content/", "./content/"):
        if p_raw.startswith(likely):
            variants.add(p_raw[len(likely):].lstrip("/\\"))

    base = os.path.basename(p_raw)
    if base:
        variants.add(os.path.join("val2017", base))

    for v in variants:
        found = _try(v)
        if found:
            return found

    return None

def _coerce_label(label_raw, num_choices):
    if isinstance(label_raw, str):
        s = label_raw.strip().upper()
        if len(s) == 1 and s in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
            idx = ord(s) - ord("A")
            if 0 <= idx < num_choices:
                return idx

    lab = int(label_raw)
    if num_choices == 4 and lab in (1, 2, 3, 4):
        return lab - 1
    return lab


def approx_95_ci(p, n):
    if n <= 0:
        return (float("nan"), float("nan"))
    se = math.sqrt(p * (1 - p) / n)
    lo, hi = p - 1.96 * se, p + 1.96 * se
    return (max(0.0, lo), min(1.0, hi))

import os
import math
import torch
import pandas as pd
from PIL import Image
from tqdm.auto import tqdm

from transformers import AutoModel, AutoProcessor

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

SIGLIP_MODEL_ID = "google/siglip-base-patch16-256-multilingual"

siglip_model = AutoModel.from_pretrained(SIGLIP_MODEL_ID).to(DEVICE).eval()
siglip_processor = AutoProcessor.from_pretrained(SIGLIP_MODEL_ID)

@torch.inference_mode()
def score_image_captions(image, captions):
    inputs = siglip_processor(
        text=captions,
        images=image,
        padding='max_length',
        truncation=True,
        return_tensors="pt"
    ).to(DEVICE)

    # Get embeddings
    outputs = siglip_model(**inputs)

    img_feat = outputs.image_embeds  # (1, D)
    txt_feat = outputs.text_embeds   # (N, D)

    # Normalize + cosine similarity
    img_feat = img_feat / img_feat.norm(dim=-1, keepdim=True)
    txt_feat = txt_feat / txt_feat.norm(dim=-1, keepdim=True)
    sims = (img_feat @ txt_feat.T)[0]  # (N,)

    return sims

@torch.inference_mode()
def eval_mcq(
    csv_path,
    image_roots=(".",),
    image_col="image_path",
    label_col="correct_answer",
    caption_col_template="caption_{}",
    num_choices=4,
    strip_prefixes=(),
    max_examples=None,
    skip_missing=False,
):
    df = pd.read_csv(csv_path)
    if max_examples is not None:
        df = df.iloc[:max_examples].copy()

    needed = [image_col, label_col] + [caption_col_template.format(i) for i in range(num_choices)]
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise ValueError(
            f"Missing columns in {csv_path}: {missing}\n"
            f"Available columns: {list(df.columns)}"
        )

    correct = 0
    preds, labels = [], []
    used = 0

    for i, row in tqdm(df.iterrows(), total=len(df)):
        img_path = resolve_image_path(
            row[image_col],
            image_roots=image_roots,
            strip_prefixes=strip_prefixes,
        )

        if not img_path:
            if skip_missing:
                continue
            raise FileNotFoundError(
                f"Could not find image for row {i}.\n"
                f"CSV value: {row[image_col]}\n"
                f"Tried roots: {list(image_roots)}\n"
                f"Tip: set image_roots to the directory that CONTAINS val2017/."
            )

        image = Image.open(img_path).convert("RGB")
        captions = [str(row[caption_col_template.format(j)]) for j in range(num_choices)]

        sims = score_image_captions(image, captions)
        pred = int(sims.argmax().item())
        label = _coerce_label(row[label_col], num_choices)

        preds.append(pred)
        labels.append(label)
        correct += (pred == label)
        used += 1

    acc = correct / used if used else 0.0
    return {"acc": acc, "correct": int(correct), "total": int(used), "preds": preds, "labels": labels}

ENG_CSV = "/content/COCO_val_mcq_llama3.1_rephrased.csv"
CHI_CSV = "/content/chinese.csv"

STRIP_PREFIXES = ("data/coco/images/", "/content/")
IMAGE_ROOTS = [
    ".",          # repo root
    "/content",   # Colab
]

eng = eval_mcq(ENG_CSV, image_roots=IMAGE_ROOTS, strip_prefixes=STRIP_PREFIXES)
chi = eval_mcq(CHI_CSV, image_roots=IMAGE_ROOTS, strip_prefixes=STRIP_PREFIXES)

print(f"English: {eng['acc']:.4f} ({eng['correct']}/{eng['total']})  CI~{approx_95_ci(eng['acc'], eng['total'])}")
print(f"Chinese: {chi['acc']:.4f} ({chi['correct']}/{chi['total']})  CI~{approx_95_ci(chi['acc'], chi['total'])}")

ENG_CSV = "/content/COCO_val_mcq_llama3.1_rephrased.csv"
CHI_CSV = "/content/chinese.csv"

STRIP_PREFIXES = ("data/coco/images/", "/content/")
IMAGE_ROOTS = [
    ".",          # repo root
    "/content",   # Colab
]

eng = eval_mcq(ENG_CSV, image_roots=IMAGE_ROOTS, strip_prefixes=STRIP_PREFIXES)
chi = eval_mcq(CHI_CSV, image_roots=IMAGE_ROOTS, strip_prefixes=STRIP_PREFIXES)

print(f"English: {eng['acc']:.4f} ({eng['correct']}/{eng['total']})  CI~{approx_95_ci(eng['acc'], eng['total'])}")
print(f"Chinese: {chi['acc']:.4f} ({chi['correct']}/{chi['total']})  CI~{approx_95_ci(chi['acc'], chi['total'])}")

ARA_CSV = "/content/arabic.csv"
GRE_CSV = "/content/greek.csv"
RUS_CSV = "/content/russian.csv"
TAG_CSV = "/content/tagalog.csv"
SPA_CSV = "/content/spanish.csv"

for name, path in [
    ("Arabic",  ARA_CSV),
    ("Greek",   GRE_CSV),
    ("Russian", RUS_CSV),
    ("Tagalog", TAG_CSV),
    ("Spanish", SPA_CSV),
]:
    res = eval_mcq(path, image_roots=IMAGE_ROOTS, strip_prefixes=STRIP_PREFIXES)
    print(f"{name}: {res['acc']:.4f} ({res['correct']}/{res['total']})  CI~{approx_95_ci(res['acc'], res['total'])}")